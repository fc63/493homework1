import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
import gensim.downloader as api
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
import re
from bs4 import BeautifulSoup
import nltk

nltk.download("stopwords")
nltk.download("punkt")
nltk.download("wordnet")

!wget https://lazyprogrammer.me/course_files/nlp/tmdb_5000_movies.csv

df = pd.read_csv("tmdb_5000_movies.csv", usecols=["id", "title", "overview"])
df = df.dropna()

stop_words = set(stopwords.words("english"))
lemmatizer = WordNetLemmatizer()


def clean(text):
    clean_text = BeautifulSoup(text, "html.parser").get_text()
    clean_text = clean_text.lower()
    words = word_tokenize(clean_text)
    words = [
        lemmatizer.lemmatize(word)
        for word in words
        if word not in stop_words and re.match(r"^[a-zA-Z0-9]+$", word)
    ]
    return " ".join(words)


df["clean_overview"] = df["overview"].apply(clean)

pretrained_w2v = api.load("word2vec-google-news-300")
pretrained_glove = api.load("glove-wiki-gigaword-300")
pretrained_fasttext = api.load("fasttext-wiki-news-subwords-300")


def get_word2vec_vector(text):
    words = text.split()
    word_vecs = [pretrained_w2v[word] for word in words if word in pretrained_w2v]
    if len(word_vecs) > 0:
        return np.mean(word_vecs, axis=0)
    else:
        return np.zeros(300)


def get_glove_vector(text):
    words = text.split()
    word_vecs = [pretrained_glove[word] for word in words if word in pretrained_glove]
    if len(word_vecs) > 0:
        return np.mean(word_vecs, axis=0)
    else:
        return np.zeros(300)


def get_fasttext_vector(text):
    words = text.split()
    word_vecs = [
        pretrained_fasttext[word] for word in words if word in pretrained_fasttext
    ]
    if len(word_vecs) > 0:
        return np.mean(word_vecs, axis=0)
    else:
        return np.zeros(300)


df["word2vec_vector"] = df["clean_overview"].apply(get_word2vec_vector)
df["glove_vector"] = df["clean_overview"].apply(get_glove_vector)
df["fasttext_vector"] = df["clean_overview"].apply(get_fasttext_vector)


def recommendation_word2vec(title):
    indices = pd.Series(df.index, index=df["title"]).drop_duplicates()
    idx = indices[title]

    query_vec = df.loc[idx, "word2vec_vector"].reshape(1, -1)
    cosine_similarities = cosine_similarity(
        query_vec, np.vstack(df["word2vec_vector"].values)
    )

    sim_scores = list(enumerate(cosine_similarities[0]))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)
    sim_scores = sim_scores[1:6]

    movie_indices = [i[0] for i in sim_scores]
    recommended_movies = df.iloc[movie_indices]["title"]

    return recommended_movies, sim_scores


def recommendation_glove(title):
    indices = pd.Series(df.index, index=df["title"]).drop_duplicates()
    idx = indices[title]

    query_vec = df.loc[idx, "glove_vector"].reshape(1, -1)
    cosine_similarities = cosine_similarity(
        query_vec, np.vstack(df["glove_vector"].values)
    )

    sim_scores = list(enumerate(cosine_similarities[0]))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)
    sim_scores = sim_scores[1:6]

    movie_indices = [i[0] for i in sim_scores]
    recommended_movies = df.iloc[movie_indices]["title"]

    return recommended_movies, sim_scores


def recommendation_fasttext(title):
    indices = pd.Series(df.index, index=df["title"]).drop_duplicates()
    idx = indices[title]

    query_vec = df.loc[idx, "fasttext_vector"].reshape(1, -1)
    cosine_similarities = cosine_similarity(
        query_vec, np.vstack(df["fasttext_vector"].values)
    )

    sim_scores = list(enumerate(cosine_similarities[0]))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)
    sim_scores = sim_scores[1:6]

    movie_indices = [i[0] for i in sim_scores]
    recommended_movies = df.iloc[movie_indices]["title"]

    return recommended_movies, sim_scores


def compare_recommendations(title):
    print(f"For the movie: {title}")

    recommended_movies_w2v, sim_scores_w2v = recommendation_word2vec(title)
    print("\nMovies recommended using Word2Vec:")
    for i, (movie, score) in enumerate(zip(recommended_movies_w2v, sim_scores_w2v), 1):
        print(f"{i}. {movie} - Score: {score[1]:.4f}")

    recommended_movies_glove, sim_scores_glove = recommendation_glove(title)
    print("\nMovies recommended using GloVe:")
    for i, (movie, score) in enumerate(
        zip(recommended_movies_glove, sim_scores_glove), 1
    ):
        print(f"{i}. {movie} - Score: {score[1]:.4f}")

    recommended_movies_fasttext, sim_scores_fasttext = recommendation_fasttext(title)
    print("\nMovies recommended using FastText:")
    for i, (movie, score) in enumerate(
        zip(recommended_movies_fasttext, sim_scores_fasttext), 1
    ):
        print(f"{i}. {movie} - Score: {score[1]:.4f}")


query_film = "The Matrix"
compare_recommendations(query_film)
