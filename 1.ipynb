import pandas as pd
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
import gensim.downloader as api
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize  
from nltk.stem import WordNetLemmatizer
from sklearn.feature_extraction.text import TfidfVectorizer
import re
from bs4 import BeautifulSoup
import nltk

nltk.download('stopwords')
nltk.download('punkt')
nltk.download('wordnet')

!wget https://lazyprogrammer.me/course_files/nlp/tmdb_5000_movies.csv

df = pd.read_csv('tmdb_5000_movies.csv', usecols=['id', 'title', 'overview'])
df = df.dropna()  

stop_words = set(stopwords.words('english'))
lemmatizer = WordNetLemmatizer()

def clean(text):
    clean_text = BeautifulSoup(text, "html.parser").get_text()  
    clean_text = clean_text.lower()  
    words = word_tokenize(clean_text)  
    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words and re.match(r'^[a-zA-Z0-9]+$', word)]  
    return ' '.join(words)

df['clean_overview'] = df['overview'].apply(clean)

pretrained_model = api.load('word2vec-google-news-300')

def get_word2vec_vector(text):
    words = text.split()
    word_vecs = [pretrained_model[word] for word in words if word in pretrained_model]
    if len(word_vecs) > 0:
        return np.mean(word_vecs, axis=0)  
    else:
        return np.zeros(300)  

df['word2vec_vector'] = df['clean_overview'].apply(get_word2vec_vector)

tfidf = TfidfVectorizer(analyzer='word', ngram_range=(1, 2), min_df=2, stop_words='english')
tfidf_vectors = tfidf.fit_transform(df['clean_overview'])
tfidf_feature_names = tfidf.get_feature_names_out()

def get_tfidf_weighted_word2vec_vector(text, idx):
    words = text.split()
    weighted_word_vector = np.zeros(300)
    weighted_sum = 0
    for word in words:
        if word in pretrained_model and word in tfidf_feature_names:
            word_vec = pretrained_model[word]
            tfidf_weight = tfidf_vectors[idx, tfidf.vocabulary_.get(word)]
            weighted_word_vector += word_vec * tfidf_weight
            weighted_sum += tfidf_weight
    if weighted_sum != 0:
        weighted_word_vector /= weighted_sum
    return weighted_word_vector

df['word2vec_tfidf_vector'] = [get_tfidf_weighted_word2vec_vector(text, idx) for idx, text in enumerate(df['clean_overview'])]

def recommendation_word2vec(title):
    indices = pd.Series(df.index, index=df['title']).drop_duplicates()
    idx = indices[title]  

    query_vec = df.loc[idx, 'word2vec_vector'].reshape(1, -1)  

    cosine_similarities = cosine_similarity(query_vec, np.vstack(df['word2vec_vector'].values))  

    sim_scores = list(enumerate(cosine_similarities[0]))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)
    sim_scores = sim_scores[1:6]  

    movie_indices = [i[0] for i in sim_scores]
    recommended_movies = df.iloc[movie_indices]['title']

    return recommended_movies, sim_scores

def recommendation_word2vec_tfidf(title):
    indices = pd.Series(df.index, index=df['title']).drop_duplicates()
    idx = indices[title]  

    query_vec = df.loc[idx, 'word2vec_tfidf_vector'].reshape(1, -1)  

    cosine_similarities = cosine_similarity(query_vec, np.vstack(df['word2vec_tfidf_vector'].values))  

    sim_scores = list(enumerate(cosine_similarities[0]))
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)
    sim_scores = sim_scores[1:6]  

    movie_indices = [i[0] for i in sim_scores]
    recommended_movies = df.iloc[movie_indices]['title']

    return recommended_movies, sim_scores

query_film = "The Matrix"

recommended_movies_w2v, sim_scores_w2v = recommendation_word2vec(query_film)

recommended_movies_w2v_tfidf, sim_scores_w2v_tfidf = recommendation_word2vec_tfidf(query_film)

print(f"Film: {query_film} için")
print("Word2Vec ile önerilen filmler:")
for i, (movie, score) in enumerate(zip(recommended_movies_w2v, sim_scores_w2v), 1):
    print(f"{i}. {movie} - Benzerlik skoru: {score[1]:.4f}")

print("\nWord2Vec + TF-IDF ile önerilen filmler:")
for i, (movie, score) in enumerate(zip(recommended_movies_w2v_tfidf, sim_scores_w2v_tfidf), 1):
    print(f"{i}. {movie} - Benzerlik skoru: {score[1]:.4f}")
